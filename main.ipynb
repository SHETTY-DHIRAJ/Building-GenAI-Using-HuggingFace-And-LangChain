{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Hugging Face Models using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id= \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "# Here in bellow code the HF_TOKEN is the token which is used to access the model from the huggingface hub. This token is stored in the .env file. You can get this token from the huggingface hub by creating an account on the huggingface and then go to the settings and then click on the API token and then copy the token and paste it in the .env file.\n",
    "llm= HuggingFaceEndpoint(repo_id= repo_id,\n",
    "                         max_length= 128,\n",
    "                         temperature= 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMachine learning is a type of artificial intelligence (AI) that allows computer systems to automatically improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nHow does machine learning work?\\n\\nMachine learning algorithms build a mathematical model based on input data, and then use that model to make predictions or decisions without being explicitly programmed to perform the task. There are three types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.\\n\\n1. Supervised learning: In supervised learning, the machine is provided with labeled data, which means that the correct answer is provided along with the input data. The machine learns from this data and uses it to make predictions or decisions without being explicitly programmed to perform the task.\\n2. Unsupervised learning: In unsupervised learning, the machine is provided with unlabeled data, which means that there is no correct answer provided along with the input data. The machine learns from this data by looking for patterns and structures in the data and organizing it accordingly.\\n3. Reinforcement learning: In reinforcement learning, the machine learns from its own actions and their consequences. The machine receives rewards or penalties based on its actions and uses this feedback to learn how to take actions that will maximize its reward.\\n\\nApplications of Machine Learning\\n\\nMachine learning has a wide range of applications in various industries such as healthcare, finance, education, transportation, marketing, and more. Some common applications of machine learning include:\\n\\n1. Image recognition and classification: Machine learning algorithms can be used to recognize and classify images based on their features, such as facial recognition, object recognition, and image segmentation.\\n2. Speech recognition: Machine learning algorithms can be used to recognize and transcribe spoken language into text.\\n3. Fraud detection: Machine learning algorithms can be used to detect fraudulent transactions by analyzing patterns in data and identifying anomalies.\\n4. Predictive maintenance: Machine learning algorithms can be used to predict equipment failures and schedule maintenance accordingly, reducing downtime and'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Let's try different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "repo_id= \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "llm= HuggingFaceEndpoint(repo_id= repo_id,\n",
    "                         max_length= 128,\n",
    "                         temperature= 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\\n\\nMachine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence (AI) based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\\n\\nMachine learning algorithms are used to perform a variety of tasks, including:\\n\\n1. Classification: Classifying data into different categories based on features. For example, classifying emails as spam or not spam.\\n2. Regression: Predicting a continuous value based on input features. For example, predicting the price of a house based on features such as its size, location, and number of bedrooms.\\n3. Clustering: Grouping similar data points together. For example, grouping customers based on their purchasing behavior.\\n4. Anomaly detection: Identifying unusual or abnormal data points. For example, detecting fraudulent credit card transactions.\\n5. Natural language processing: Understanding and interpreting human language. For example, using machine learning to power virtual assistants such as Siri and Alexa.\\n\\nMachine learning models are typically trained on large datasets, and the performance of the model is evaluated based on its ability to accurately predict or classify new data. There are several different approaches to machine learning, including supervised learning, unsupervised learning, and reinforcement learning.\\n\\nSupervised learning is a type of machine learning where the model is trained on labeled data, meaning that the input data is accompanied by the correct output. The goal is for the model to learn the relationship between the input and output data so that it can accurately predict the output for new, unseen data.\\n\\nUnsupervised learning is a type of machine learning where the model is trained on unlabeled data, meaning that there is no correct output. The goal is for the model to find patterns and structure in the data on its own.\\n\\nReinforcement learning is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives rewards or punishments based on its actions, and the goal is for the agent to learn a policy that maximizes its reward over time.\\n\\nMachine learning is a'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create some PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\" Question: {question}\\nAnswer: Let's think step by step.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template= \"\"\" Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt= PromptTemplate(template= template, input_variables= [\"question\"])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How transformer works in LLMS?',\n",
       " 'text': ' In Language Modeling, the goal is to predict the next word in a sequence given the context of the previous words. Transformers are a type of deep learning model that have been very successful in tasks like this.\\n\\nIn the context of Longformer, a Long Distance Attention Transformer for Text Classification, and Performer, a Linear Attention Transformer for Long Context, the transformer works as follows:\\n\\n1. Tokenization: The input text is first tokenized into subwords or words. Each token is assigned a unique integer ID.\\n\\n2. Position Encoding: Since the transformer only considers tokens that are close in the sequence, position encoding is used to provide information about the relative position of each token in the sequence.\\n\\n3. Attention Mechanism: The transformer uses an attention mechanism to weigh the importance of each token when predicting the next word. For each token, it computes a weighted sum of all other tokens, where the weights are determined by a dot product and a softmax function. This allows the model to focus on relevant parts of the sequence.\\n\\n4. Feed Forward Network: After the attention step, the weights are passed through a feed-forward network (two linear layers with a ReLU activation in between) to produce the final output.\\n\\n5. Training: The model is trained on a large corpus of text using a loss function that encourages the model to predict the next word correctly given the context.\\n\\nIn the context of LLMs like LaMDA (Language Model for Dialogue Applications) and BERT (Bidirectional Encoder Representations from Transformers), the transformer is used to encode the input text into a set of vectors that capture the semantic meaning of the text. These vectors can then be used for various tasks such as question answering, sentiment analysis, and text generation.\\n\\nIn summary, the transformer in LLMs works by using an attention mechanism to weigh the importance of each token in the input sequence, and a feed-forward network to transform these weights into a final output. The model is trained on a large corpus of text to learn to predict the next word given the context.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain= LLMChain(llm= llm, prompt= prompt)\n",
    "\n",
    "question= \"How transformer works in LLMS?\"\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create the HuggingFace Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Here the model will be running locally on the system.\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=100)\n",
    "hf= HuggingFacePipeline(pipeline= pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Langchain is a multi-party blockchain library that provides a tool to connect and store assets. A simple view of your assets is now displayed:\\n\\n\\nThe following code demonstrates how you can use the system's library to view your entire portfolio:\\n\\n\\nI can't say I've tried the above system before, but I am confident any time you see those little images in your Twitter feed the right thing in the right place to visualize your portfolio.\\n\\nWhat I also found was that it would be really useful to\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.invoke(\"Langchain is a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Let's use Hugging Face Pipeline with GPU\n",
    "###### Note: The current device is GPU-enabled by default, which is why the previous code ran on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Here the Cuda version should be the same as per the one required by PyTorch. Try running the below command in terminal to install the PyTorch with the required Cuda version.\n",
    "# pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "import torch\n",
    "\n",
    "# torch.cuda.is_available() returns True if a GPU is available, False if not\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use GPU (device=0) if available, otherwise use CPU (device=-1)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpu_llm= HuggingFacePipeline.from_model_id(\n",
    "    model_id= \"gpt2\",\n",
    "    task= \"text-generation\",\n",
    "    device=device,  # Pass the selected device (0 for GPU or -1 for CPU)\n",
    "    pipeline_kwargs= {\"max_new_tokens\": 100},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here in the below code we are creating a chain in different way.\n",
    "\n",
    "chain= prompt | gpu_llm  # Here we are utilizing the previously created prompt and gpu_llm to create a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Question: What is machine learning?\\nAnswer: Let's think step by step.\\nLet's see how machine learning works in three basic areas:\\nThe first is machine learning, applied to the input-output pipeline (or the data source in the previous lesson)\\nand the other two are machine learning in general, where neural networks are used to learn more information relative to the input dataset\\nand neural networks are used to learn more information relative to the dataset Learning about the input data to create a neural network (as we said in my previous example of learning about the data)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question= \"What is machine learning?\"\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in various outputs we do see the model hallucinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
